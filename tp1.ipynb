{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d72e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.18.0 / PyTorch 2.7.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7017d3b",
   "metadata": {},
   "source": [
    "#Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9163cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distributed_datasets(k: int, alpha: float, save_dir: str) -> None:\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    train_data = datasets.FashionMNIST(\n",
    "        root=\"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "    )\n",
    "    \n",
    "    targets = np.array(train_data.targets)\n",
    "    data = np.array(train_data.data)\n",
    "\n",
    "    num_classes = len(np.unique(targets))\n",
    "    class_indices = [np.where(targets == y)[0] for y in range(num_classes)]\n",
    "\n",
    "    client_indices = [[] for _ in range(k)]\n",
    "    for c in range(num_classes):\n",
    "        class_idx = class_indices[c]\n",
    "        np.random.shuffle(class_idx)\n",
    "\n",
    "        proportions = np.random.dirichlet(alpha=np.repeat(alpha, k))\n",
    "        proportions = (np.cumsum(proportions) * len(class_idx)).astype(int)[:-1]\n",
    "        split_indices = np.split(class_idx, proportions)\n",
    "\n",
    "        for i, idx in enumerate(split_indices):\n",
    "            client_indices[i].extend(idx.tolist())\n",
    "\n",
    "    for i, indices in enumerate(client_indices):\n",
    "        client_data = data[indices]\n",
    "        client_targets = targets[indices]\n",
    "        \n",
    "        flat_images = client_data.reshape(len(client_data), -1)\n",
    "        df = pd.DataFrame(flat_images)\n",
    "        df['label'] = client_targets\n",
    "        \n",
    "        df.to_csv(os.path.join(save_dir, f'client_{i}.csv'), index=False)\n",
    "\n",
    "    print(f\"Distributed datasets saved to {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49916822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:03<00:00, 6.77MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 1.03MB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:00<00:00, 6.84MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 8.87MB/s]\n",
      "/var/folders/h0/pzm07l6x5n7181rc09xppl940000gn/T/ipykernel_83832/3333435157.py:18: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  targets = np.array(train_data.targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed datasets saved to client_data\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_CLIENTS = 5\n",
    "ALPHA = 1.5\n",
    "SAVE_PATH = \"client_data\"\n",
    "\n",
    "generate_distributed_datasets(NUM_OF_CLIENTS, ALPHA, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab0debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_client_data(cid: int, data_dir: str, batch_size: int) -> tuple[DataLoader, DataLoader]:\n",
    "    df = pd.read_csv(os.path.join(data_dir, f'client_{cid}.csv'))\n",
    "\n",
    "    # Separate features and labels\n",
    "    X = df.drop(columns=[\"label\"]).values.astype(\"float32\") / 255.0  # normalize\n",
    "    y = df[\"label\"].values.astype(\"int64\")\n",
    "\n",
    "    # Reshape X to N x 1 x 28 x 28 (needed for CNNs)\n",
    "    X = X.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    # Train/val split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.tensor(X_train)\n",
    "    y_train_tensor = torch.tensor(y_train)\n",
    "    X_val_tensor = torch.tensor(X_val)\n",
    "    y_val_tensor = torch.tensor(y_val)\n",
    "\n",
    "    # Create datasets and loaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d533b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_OF_CLIENTS):\n",
    "  train_dataloader, val_dataloader = load_client_data(i, SAVE_PATH, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd7b8b6",
   "metadata": {},
   "source": [
    "#Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e85b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class CustomFashionModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # this is where i create the model itself\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [batch, 32, 14, 14]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [batch, 64, 7, 7]\n",
    "        x = x.view(x.size(0), -1)             # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def train_epoch(self, train_loader: DataLoader,\n",
    "                    criterion: nn.Module,\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    device: torch.device) -> tuple[float, float]:\n",
    "        self.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        avg_loss = running_loss / total\n",
    "        accuracy = correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def test_epoch(self, test_loader: DataLoader,\n",
    "                   criterion: nn.Module,\n",
    "                   device: torch.device) -> tuple[float, float]:\n",
    "        self.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        avg_loss = running_loss / total\n",
    "        accuracy = correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def get_model_parameters(self) -> List[np.ndarray]:\n",
    "        return [param.detach().cpu().numpy() for param in self.state_dict().values()]\n",
    "\n",
    "    def set_model_parameters(self, parameters: List[np.ndarray]) -> None:\n",
    "        state_dict = self.state_dict()\n",
    "        for key, param_array in zip(state_dict.keys(), parameters):\n",
    "            param_tensor = torch.tensor(param_array)\n",
    "            state_dict[key].copy_(param_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc86848",
   "metadata": {},
   "source": [
    "#Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd39d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import (\n",
    "    GetPropertiesIns, GetPropertiesRes,\n",
    "    GetParametersIns, GetParametersRes,\n",
    "    FitIns, FitRes,\n",
    "    EvaluateIns, EvaluateRes,\n",
    "    Code, Status,\n",
    "    ndarrays_to_parameters, parameters_to_ndarrays\n",
    ")\n",
    "\n",
    "from typing import List\n",
    "import torch\n",
    "\n",
    "class CustomClient(flwr.client.Client):\n",
    "    def __init__(self, model: torch.nn.Module, train_loader,\n",
    "                 test_loader, device: torch.device) -> None:\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def get_properties(self, instruction: GetPropertiesIns) -> GetPropertiesRes:\n",
    "        return GetPropertiesRes(\n",
    "            status=Status(code=Code.OK, message=\"Success\"),\n",
    "            properties={\"framework\": \"pytorch\", \"dataset\": \"FashionMNIST\"}\n",
    "        )\n",
    "\n",
    "    def get_parameters(self, instruction: GetParametersIns) -> GetParametersRes:\n",
    "        weights: List[np.ndarray] = self.model.get_model_parameters()\n",
    "        return GetParametersRes(\n",
    "            status=Status(code=Code.OK, message=\"Success\"),\n",
    "            parameters=ndarrays_to_parameters(weights)\n",
    "        )\n",
    "\n",
    "    def fit(self, instruction: FitIns) -> FitRes:\n",
    "        # Set model parameters from server\n",
    "        params = parameters_to_ndarrays(instruction.parameters)\n",
    "        self.model.set_model_parameters(params)\n",
    "\n",
    "        # Training\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        self.model.to(self.device)\n",
    "        train_loss, train_accuracy = self.model.train_epoch(\n",
    "            self.train_loader, criterion, optimizer, self.device\n",
    "        )\n",
    "\n",
    "        # Return updated parameters\n",
    "        updated_weights = self.model.get_model_parameters()\n",
    "        return FitRes(\n",
    "            status=Status(code=Code.OK, message=\"Trained successfully\"),\n",
    "            parameters=ndarrays_to_parameters(updated_weights),\n",
    "            num_examples=len(self.train_loader.dataset),\n",
    "            metrics={\"train_loss\": train_loss, \"train_accuracy\": train_accuracy}\n",
    "        )\n",
    "\n",
    "    def evaluate(self, instruction: EvaluateIns) -> EvaluateRes:\n",
    "        # Set model parameters from server\n",
    "        params = parameters_to_ndarrays(instruction.parameters)\n",
    "        self.model.set_model_parameters(params)\n",
    "\n",
    "        # Evaluation\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.model.to(self.device)\n",
    "        test_loss, test_accuracy = self.model.test_epoch(\n",
    "            self.test_loader, criterion, self.device\n",
    "        )\n",
    "\n",
    "        return EvaluateRes(\n",
    "            status=Status(code=Code.OK, message=\"Evaluated successfully\"),\n",
    "            loss=test_loss,\n",
    "            num_examples=len(self.test_loader.dataset),\n",
    "            metrics={\"accuracy\": test_accuracy}\n",
    "        )\n",
    "\n",
    "    def to_client(self) -> \"CustomClient\":\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b14603dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pty.py:95: DeprecationWarning: This process (pid=83832) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower SuperNode\n",
      "\u001b[93mWARNING \u001b[0m:   Option `--insecure` was set. Starting insecure HTTP channel to 127.0.0.1:8080.\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ClientAppIo gRPC server on 0.0.0.0:9094\n",
      "\u001b[93mWARNING \u001b[0m:   Connection attempt failed, retrying...\n",
      "\u001b[93mWARNING \u001b[0m:   Connection attempt failed, retrying in 1.22 seconds\n",
      "\u001b[93mWARNING \u001b[0m:   Connection attempt failed, retrying in 0.57 seconds\n",
      "\u001b[93mWARNING \u001b[0m:   Connection attempt failed, retrying in 0.66 seconds\n",
      "\u001b[93mWARNING \u001b[0m:   Connection attempt failed, retrying in 13.68 seconds\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/flwr/common/retry_invoker.py\"\u001b[0m, line \u001b[35m276\u001b[0m, in \u001b[35minvoke\u001b[0m\n",
      "    ret = target(*args, **kwargs)\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/grpc/_interceptor.py\"\u001b[0m, line \u001b[35m277\u001b[0m, in \u001b[35m__call__\u001b[0m\n",
      "    response, ignored_call = \u001b[31mself._with_call\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                             \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mrequest,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "    ...<4 lines>...\n",
      "        \u001b[1;31mcompression=compression,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/grpc/_interceptor.py\"\u001b[0m, line \u001b[35m332\u001b[0m, in \u001b[35m_with_call\u001b[0m\n",
      "    return \u001b[31mcall.result\u001b[0m\u001b[1;31m()\u001b[0m, call\n",
      "           \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/grpc/_channel.py\"\u001b[0m, line \u001b[35m440\u001b[0m, in \u001b[35mresult\u001b[0m\n",
      "    raise self\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/grpc/_interceptor.py\"\u001b[0m, line \u001b[35m315\u001b[0m, in \u001b[35mcontinuation\u001b[0m\n",
      "    response, call = \u001b[31mself._thunk(new_method).with_call\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mrequest,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "    ...<4 lines>...\n",
      "        \u001b[1;31mcompression=new_compression,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/grpc/_channel.py\"\u001b[0m, line \u001b[35m1198\u001b[0m, in \u001b[35mwith_call\u001b[0m\n",
      "    return _end_unary_response_blocking(state, call, True, None)\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/grpc/_channel.py\"\u001b[0m, line \u001b[35m1006\u001b[0m, in \u001b[35m_end_unary_response_blocking\u001b[0m\n",
      "    \u001b[1;31mraise _InactiveRpcError(state)\u001b[0m  # pytype: disable=not-instantiable\n",
      "    \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mgrpc._channel._InactiveRpcError\u001b[0m: \u001b[35m<_InactiveRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.UNAVAILABLE\n",
      "\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8080: Failed to connect to remote host: connect: Connection refused (61)\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-05-22T15:26:31.163628+02:00\", grpc_status:14, grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8080: Failed to connect to remote host: connect: Connection refused (61)\"}\"\n",
      ">\u001b[0m\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/bin/flower-supernode\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mrun_supernode\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/flwr/client/supernode/app.py\"\u001b[0m, line \u001b[35m83\u001b[0m, in \u001b[35mrun_supernode\u001b[0m\n",
      "    \u001b[31mstart_client_internal\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mserver_address=args.superlink,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<12 lines>...\n",
      "        \u001b[1;31mclientappio_api_address=args.clientappio_api_address,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/flwr/client/app.py\"\u001b[0m, line \u001b[35m424\u001b[0m, in \u001b[35mstart_client_internal\u001b[0m\n",
      "    if (node_id := \u001b[31mcreate_node\u001b[0m\u001b[1;31m()\u001b[0m) is None:\n",
      "                   \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/flwr/client/grpc_rere_client/connection.py\"\u001b[0m, line \u001b[35m199\u001b[0m, in \u001b[35mcreate_node\u001b[0m\n",
      "    create_node_response = retry_invoker.invoke(\n",
      "        stub.CreateNode,\n",
      "        request=create_node_request,\n",
      "    )\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/flwr/common/retry_invoker.py\"\u001b[0m, line \u001b[35m311\u001b[0m, in \u001b[35minvoke\u001b[0m\n",
      "    \u001b[31mself.wait_function\u001b[0m\u001b[1;31m(state.actual_wait)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/flwr/common/exit_handlers.py\"\u001b[0m, line \u001b[35m80\u001b[0m, in \u001b[35mgraceful_exit_handler\u001b[0m\n",
      "    \u001b[31mflwr_exit\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mcode=SIGNAL_TO_EXIT_CODE[signalnum],\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        \u001b[1;31mmessage=exit_message,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        \u001b[1;31mevent_type=event_type,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/Users/cheoso/fed_learning/venv/lib/python3.13/site-packages/flwr/common/exit/exit.py\"\u001b[0m, line \u001b[35m75\u001b[0m, in \u001b[35mflwr_exit\u001b[0m\n",
      "    \u001b[31mevent(event_type, event_details).result\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\"\u001b[0m, line \u001b[35m451\u001b[0m, in \u001b[35mresult\u001b[0m\n",
      "    \u001b[31mself._condition.wait\u001b[0m\u001b[1;31m(timeout)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\"\u001b[0m, line \u001b[35m359\u001b[0m, in \u001b[35mwait\u001b[0m\n",
      "    \u001b[31mwaiter.acquire\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n"
     ]
    },
    {
     "ename": "_MultiThreadedRendezvous",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8080: Failed to connect to remote host: connect: Connection refused (61)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-05-22T15:26:38.273837+02:00\", grpc_status:14, grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8080: Failed to connect to remote host: connect: Connection refused (61)\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_MultiThreadedRendezvous\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     37\u001b[39m     flwr.client.start_client(server_address=\u001b[33m\"\u001b[39m\u001b[33m127.0.0.1:8080\u001b[39m\u001b[33m\"\u001b[39m, client=client.to_client())\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Step 5: Start Flower client\u001b[39;00m\n\u001b[32m     36\u001b[39m get_ipython().system(\u001b[33m\"\u001b[39m\u001b[33mflower-supernode --insecure --superlink=\u001b[39m\u001b[33m'\u001b[39m\u001b[33m127.0.0.1:8080\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mflwr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_address\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m127.0.0.1:8080\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fed_learning/venv/lib/python3.13/site-packages/flwr/client/app.py:201\u001b[39m, in \u001b[36mstart_client\u001b[39m\u001b[34m(server_address, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time)\u001b[39m\n\u001b[32m    198\u001b[39m warn_deprecated_feature(name=msg)\n\u001b[32m    200\u001b[39m event(EventType.START_CLIENT_ENTER)\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[43mstart_client_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_client_app_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroot_certificates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mroot_certificates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43minsecure\u001b[49m\u001b[43m=\u001b[49m\u001b[43minsecure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauthentication_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauthentication_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m event(EventType.START_CLIENT_LEAVE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fed_learning/venv/lib/python3.13/site-packages/flwr/client/app.py:438\u001b[39m, in \u001b[36mstart_client_internal\u001b[39m\u001b[34m(server_address, node_config, load_client_app_fn, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time, flwr_path, isolation, clientappio_api_address)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    437\u001b[39m         \u001b[38;5;66;03m# Receive\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m         message = \u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    440\u001b[39m             time.sleep(\u001b[32m3\u001b[39m)  \u001b[38;5;66;03m# Wait for 3s before asking again\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fed_learning/venv/lib/python3.13/site-packages/flwr/client/grpc_client/connection.py:142\u001b[39m, in \u001b[36mgrpc_connection.<locals>.receive\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreceive\u001b[39m() -> Message:\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# Receive ServerMessage proto\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     proto = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mserver_message_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# ServerMessage proto --> *Ins --> RecordDict\u001b[39;00m\n\u001b[32m    145\u001b[39m     field = proto.WhichOneof(\u001b[33m\"\u001b[39m\u001b[33mmsg\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fed_learning/venv/lib/python3.13/site-packages/grpc/_channel.py:543\u001b[39m, in \u001b[36m_Rendezvous.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fed_learning/venv/lib/python3.13/site-packages/grpc/_channel.py:969\u001b[39m, in \u001b[36m_MultiThreadedRendezvous._next\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    967\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state.code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31m_MultiThreadedRendezvous\u001b[39m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8080: Failed to connect to remote host: connect: Connection refused (61)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-05-22T15:26:38.273837+02:00\", grpc_status:14, grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8080: Failed to connect to remote host: connect: Connection refused (61)\"}\"\n>"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "#from model import CustomFashionModel  # Make sure this path is correct\n",
    "#from client import CustomClient       # Your FLWR client class\n",
    "#from data import load_client_data     # Your data loading function\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Step 1: Parse command-line arguments\n",
    "    sys.argv = [\"notebook\", \"--cid\", \"0\", \"--data_dir\", \"client_data\", \"--batch_size\", \"32\"]\n",
    "\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description=\"Run a Flower client.\")\n",
    "    parser.add_argument(\"--cid\", type=int, required=True, help=\"Client ID\")\n",
    "    parser.add_argument(\"--data_dir\", type=str, default=SAVE_PATH, help=\"Data directory\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32, help=\"Batch size\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Step 2: Load client data\n",
    "    train_loader, test_loader = load_client_data(\n",
    "        cid=args.cid,\n",
    "        data_dir=args.data_dir,\n",
    "        batch_size=args.batch_size\n",
    "    )\n",
    "\n",
    "    # Step 3: Create model and move to device\n",
    "    model = CustomFashionModel()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Step 4: Create client instance\n",
    "    client = CustomClient(model, train_loader, test_loader, device)\n",
    "\n",
    "    # Step 5: Start Flower client\n",
    "    !flower-supernode --insecure --superlink='127.0.0.1:8080'\n",
    "    flwr.client.start_client(server_address=\"127.0.0.1:8080\", client=client.to_client())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c640a3dd",
   "metadata": {},
   "source": [
    "#Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e0ebdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, List, Optional\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "\n",
    "class CustomClientManager(ClientManager):\n",
    "    def __init__(self):\n",
    "        self._clients: Dict[str, ClientProxy] = {}\n",
    "        self._lock = threading.Lock()\n",
    "        self._clients_available = threading.Condition(lock=self._lock)\n",
    "\n",
    "    def num_available(self) -> int:\n",
    "        with self._lock:\n",
    "            return len(self._clients)\n",
    "\n",
    "    def register(self, client: ClientProxy) -> bool:\n",
    "        with self._lock:\n",
    "            client_id = client.cid\n",
    "            if client_id in self._clients:\n",
    "                return False  # Already registered\n",
    "            self._clients[client_id] = client\n",
    "            self._clients_available.notify_all()\n",
    "            return True\n",
    "\n",
    "    def unregister(self, client: ClientProxy) -> None:\n",
    "        with self._lock:\n",
    "            client_id = client.cid\n",
    "            if client_id in self._clients:\n",
    "                del self._clients[client_id]\n",
    "\n",
    "    def all(self) -> Dict[str, ClientProxy]:\n",
    "        with self._lock:\n",
    "            return dict(self._clients)  # Return a copy to avoid race conditions\n",
    "\n",
    "    def wait_for(self, num_clients: int, timeout: int) -> bool:\n",
    "        with self._clients_available:\n",
    "            start_time = time.time()\n",
    "            while len(self._clients) < num_clients:\n",
    "                remaining = timeout - (time.time() - start_time)\n",
    "                if remaining <= 0:\n",
    "                    break\n",
    "                self._clients_available.wait(timeout=remaining)\n",
    "            return len(self._clients) >= num_clients\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        num_clients: int,\n",
    "        min_num_clients: Optional[int] = None,\n",
    "        criterion: Optional[object] = None,\n",
    "    ) -> List[ClientProxy]:\n",
    "        with self._lock:\n",
    "            available_clients = list(self._clients.values())\n",
    "\n",
    "            # If criterion is specified, filter clients accordingly (optional)\n",
    "            if criterion is not None:\n",
    "                available_clients = [c for c in available_clients if criterion(c)]\n",
    "\n",
    "            # Check min_num_clients requirement\n",
    "            if min_num_clients is not None and len(available_clients) < min_num_clients:\n",
    "                return []\n",
    "\n",
    "            # Randomly sample clients if enough are available\n",
    "            if len(available_clients) < num_clients:\n",
    "                return []\n",
    "\n",
    "            sampled_clients = random.sample(available_clients, num_clients)\n",
    "            return sampled_clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64decc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Optional, Union\n",
    "import numpy as np\n",
    "\n",
    "from flwr.common import (\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy import Strategy\n",
    "\n",
    "\n",
    "class FedAvgStrategy(Strategy):\n",
    "    def __init__(self):\n",
    "        self._global_parameters: Optional[Parameters] = None\n",
    "\n",
    "    def initialize_parameters(self, client_manager: ClientManager) -> Optional[Parameters]:\n",
    "        # Initialize global parameters from one client or stored state\n",
    "        if self._global_parameters is not None:\n",
    "            return self._global_parameters\n",
    "\n",
    "        # If no global params stored, fetch from one client if available\n",
    "        clients = list(client_manager.all().values())\n",
    "        if not clients:\n",
    "            return None\n",
    "\n",
    "        parameters = clients[0].get_parameters()\n",
    "        self._global_parameters = parameters\n",
    "        return parameters\n",
    "\n",
    "    def configure_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        parameters: Parameters,\n",
    "        client_manager: ClientManager,\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        # Configure fit instructions: send current global model to all clients\n",
    "        clients = list(client_manager.all().values())\n",
    "        fit_ins = []\n",
    "        for client in clients:\n",
    "            fit_ins.append((client, FitIns(parameters, {})))  # empty config dict\n",
    "        return fit_ins\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Extract weights and num_examples from each client result\n",
    "        weights = []\n",
    "        num_examples = []\n",
    "        losses = []\n",
    "\n",
    "        for client, fit_res in results:\n",
    "            # Extract NumPy arrays from Parameters object\n",
    "            ndarrays = parameters_to_ndarrays(fit_res.parameters)\n",
    "            weights.append(ndarrays)\n",
    "            # Assume fit_res.metrics includes 'num_examples' and 'loss'\n",
    "            num_ex = fit_res.num_examples if hasattr(fit_res, \"num_examples\") else None\n",
    "            if num_ex is None:\n",
    "                # fallback: check metrics dictionary\n",
    "                num_ex = fit_res.metrics.get(\"num_examples\") if fit_res.metrics else None\n",
    "            if num_ex is None:\n",
    "                num_ex = 1  # fallback to 1 to avoid division by zero\n",
    "\n",
    "            num_examples.append(num_ex)\n",
    "\n",
    "            loss = fit_res.metrics.get(\"loss\") if fit_res.metrics else None\n",
    "            if loss is not None:\n",
    "                losses.append(loss)\n",
    "\n",
    "        # Weighted average of weights (FedAvg)\n",
    "        total_examples = sum(num_examples)\n",
    "        averaged_weights = [\n",
    "            sum(w[i] * num_examples[j] for j, w in enumerate(weights)) / total_examples\n",
    "            for i in range(len(weights[0]))\n",
    "        ]\n",
    "\n",
    "        # Convert averaged weights back to Parameters object\n",
    "        aggregated_parameters = ndarrays_to_parameters(averaged_weights)\n",
    "        self._global_parameters = aggregated_parameters\n",
    "\n",
    "        # Aggregate loss (weighted average)\n",
    "        avg_loss = sum(losses[i] * num_examples[i] for i in range(len(losses))) / total_examples if losses else 0.0\n",
    "\n",
    "        # Return new global parameters and aggregated metrics\n",
    "        return aggregated_parameters, {\"loss\": avg_loss}\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        parameters: Parameters,\n",
    "        client_manager: ClientManager,\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        # Configure evaluation instructions to all clients\n",
    "        clients = list(client_manager.all().values())\n",
    "        eval_ins = []\n",
    "        for client in clients:\n",
    "            eval_ins.append((client, EvaluateIns(parameters, {})))  # empty config dict\n",
    "        return eval_ins\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Aggregate evaluation loss and other metrics by weighted average\n",
    "        losses = []\n",
    "        num_examples = []\n",
    "\n",
    "        for client, eval_res in results:\n",
    "            loss = eval_res.loss\n",
    "            num_ex = eval_res.num_examples if hasattr(eval_res, \"num_examples\") else None\n",
    "            if num_ex is None:\n",
    "                num_ex = 1\n",
    "            losses.append(loss)\n",
    "            num_examples.append(num_ex)\n",
    "\n",
    "        total_examples = sum(num_examples)\n",
    "        avg_loss = sum(losses[i] * num_examples[i] for i in range(len(losses))) / total_examples\n",
    "\n",
    "        # Return average loss and empty dict for metrics (can be extended)\n",
    "        return avg_loss, {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df2591",
   "metadata": {},
   "source": [
    "#Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce1d991",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FedAvgStrategy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining history saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m num_rounds = \u001b[32m5\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 3. Instantiate ClientManager and Strategy\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#client_manager = CustomClientManager()\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#strategy = FedAvgStrategy()\u001b[39;00m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 4. Start the Flower server\u001b[39;00m\n\u001b[32m     17\u001b[39m history = flwr.server.start_server(\n\u001b[32m     18\u001b[39m     server_address=server_address,\n\u001b[32m     19\u001b[39m     config=flwr.server.ServerConfig(num_rounds=num_rounds),\n\u001b[32m     20\u001b[39m     client_manager=CustomClientManager,\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     strategy=\u001b[43mFedAvgStrategy\u001b[49m,\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 5. Extract history info\u001b[39;00m\n\u001b[32m     25\u001b[39m losses_distributed = history.losses_distributed\n",
      "\u001b[31mNameError\u001b[39m: name 'FedAvgStrategy' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1. Define server address\n",
    "    server_address = \"[::]:8080\"  # Listen on all interfaces on port 8080\n",
    "\n",
    "    # 2. Define federated learning hyperparameters\n",
    "    num_rounds = 5\n",
    "\n",
    "    # 3. Instantiate ClientManager and Strategy\n",
    "    #client_manager = CustomClientManager()\n",
    "    #strategy = FedAvgStrategy()\n",
    "\n",
    "    # 4. Start the Flower server\n",
    "    history = flwr.server.start_server(\n",
    "        server_address=server_address,\n",
    "        config=flwr.server.ServerConfig(num_rounds=num_rounds),\n",
    "        client_manager=CustomClientManager,\n",
    "        strategy=FedAvgStrategy,\n",
    "    )\n",
    "\n",
    "    # 5. Extract history info\n",
    "    losses_distributed = history.losses_distributed\n",
    "    metrics_distributed_fit = history.metrics_distributed_fit\n",
    "    metrics_distributed = history.metrics_distributed\n",
    "\n",
    "    # 6. Save results as JSON\n",
    "    results = {\n",
    "        \"losses_distributed\": losses_distributed,\n",
    "        \"metrics_distributed_fit\": metrics_distributed_fit,\n",
    "        \"metrics_distributed\": metrics_distributed,\n",
    "    }\n",
    "    save_path = Path(\"fl_history.json\")\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(f\"Training history saved to {save_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
